{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGRAM - 6 :Classify the data from the dataset using Multinomial Naive Bayes Classifier and calculate the accuracy,precision and recall for your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "#gathering the training data\n",
    "twenty_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "#gathering the data \n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "#creating a list of all the attributes to train the model\n",
    "categories = list(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "7532\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target [7 4 4 ... 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "#printing all the datasets and features extracted\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_test.data))\n",
    "print(twenty_train.target_names)\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")))\n",
    "print(\"Target\",twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer is a library used for feature extration from a given dataset.\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.If we do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_tf = count_vect.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
    "\n",
    "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, twenty_train.target)\n",
    "X_test_tf = count_vect.transform(twenty_test.data)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training your model successfully, it's now capable of making predictions.\n",
    "gnb.predict(X) - Perform classification on an array of test vectors X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [ 7 11  0 ...  9  3 15]\n"
     ]
    }
   ],
   "source": [
    "predicted = mnb.predict(X_test_tfidf)\n",
    "print(\"Predicted\",predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the accuracy\n",
    "\n",
    "metrics from sklearn package is used for achieving the task.\n",
    "metrics.accuracy_score(y_true, y_pred) - In multilabel classification, this function computes subset accuracy.\n",
    "The set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
    "\n",
    "y_true : 1d array-like, or label indicator array / sparse matrix. Ground truth (correct) labels.\n",
    "\n",
    "y_pred : 1d array-like, or label indicator array / sparse matrix. Predicted labels, as returned by a classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7738980350504514\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "               micro avg       0.77      0.77      0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n",
      "confusion matrix is \n",
      " [[166   0   0   1   0   1   0   0   1   1   1   3   0   6   3 123   4   8\n",
      "    0   1]\n",
      " [  1 252  15  12   9  18   1   2   1   5   2  41   4   0   6  15   4   1\n",
      "    0   0]\n",
      " [  0  14 258  45   3   9   0   2   1   3   2  25   1   0   6  23   2   0\n",
      "    0   0]\n",
      " [  0   5  11 305  17   1   3   6   1   0   2  19  13   0   5   3   1   0\n",
      "    0   0]\n",
      " [  0   3   8  23 298   0   3   8   1   3   1  16   8   0   2   8   3   0\n",
      "    0   0]\n",
      " [  1  21  17  13   2 298   1   0   1   1   0  23   0   1   4  10   2   0\n",
      "    0   0]\n",
      " [  0   1   3  31  12   1 271  19   4   4   6   5  12   6   3   9   3   0\n",
      "    0   0]\n",
      " [  0   1   0   3   0   0   4 364   3   2   2   4   1   1   3   3   4   0\n",
      "    1   0]\n",
      " [  0   0   0   1   0   0   2  10 371   0   0   4   0   0   0   8   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   0   4   0 357  22   0   0   0   2   9   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   4 387   1   0   0   1   5   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   0   1   1   3   0   0   0 383   1   0   0   3   1   0\n",
      "    0   0]\n",
      " [  0   4   2  17   5   0   2   8   7   1   2  78 235   3  11  15   2   1\n",
      "    0   0]\n",
      " [  2   3   0   1   1   3   1   0   2   3   4  11   5 292   6  52   6   4\n",
      "    0   0]\n",
      " [  0   2   0   1   0   3   0   2   1   0   1   6   1   2 351  19   4   0\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   0   1   0   0   0   0   1   2 392   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   2   0   1   1   0  10   0   0   1   6 341   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   2   0   0   0  24   3 344\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   1   0   0   1  11   0   1   7  35 118   5\n",
      "  129   0]\n",
      " [ 33   2   0   0   0   0   0   0   0   1   1   3   0   4   4 131  29   5\n",
      "    3  35]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(twenty_test.target, predicted))\n",
    "print(classification_report(twenty_test.target,predicted,target_names=twenty_test.target_names))\n",
    "\n",
    "print(\"confusion matrix is \\n\",metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
